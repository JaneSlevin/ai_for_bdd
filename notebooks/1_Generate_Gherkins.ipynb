{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0f41d3",
   "metadata": {},
   "source": [
    "In this notebook, we make API requests to OpenRouter, to generate Gherkins from user stories using various models and various prompting approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c53d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import chardet # To detect file encodings\n",
    "import asyncio\n",
    "import httpx\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "or_token = os.getenv(\"openrouter_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8cbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data_dir = Path(\"../data/user_stories/sample_data\")\n",
    "experiment_dir = Path(\"../data/gherkins/sample_data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c373f35",
   "metadata": {},
   "source": [
    "#### Load user story data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfadf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse user stories from a .txt file or all .txt files in a folder\n",
    "def parse_user_stories(path):\n",
    "    user_stories = {}\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        files = [path] # Single .txt file\n",
    "    elif os.path.isdir(path):\n",
    "        files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.txt')] # All .txt files in folder\n",
    "    else:\n",
    "        raise ValueError(f\"Path '{path}' is not a valid file or folder.\")\n",
    "        \n",
    "    for filepath in files:\n",
    "        filename = os.path.splitext(os.path.basename(filepath))[0] # Remove extension\n",
    "\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f, start=1):\n",
    "                us = line.strip()\n",
    "                if us:  # Skip empty lines\n",
    "                    us_id = f\"{filename}_{i}\"\n",
    "                    user_stories[us_id] = us\n",
    "\n",
    "    return user_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930e10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user story dictionary, creating ID keys based on filename and line number\n",
    "us_dict = parse_user_stories(us_data_dir / \"g04-recycling.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4500ca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(us_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5507ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate user stories\n",
    "us_list = list(us_dict.values())\n",
    "\n",
    "len(us_list) == len(set(us_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b867413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'g04-recycling_1': 'As a user, I want to click on the address, so that it takes me to a new tab with Google Maps.',\n",
       " 'g04-recycling_2': 'As a user, I want to be able to anonymously view public information, so that I know about recycling centers near me before creating an account.',\n",
       " 'g04-recycling_3': 'As a user, I want to be able to enter my zip code and get a list of nearby recycling facilities, so that I can determine which ones I should consider.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample subset of user stories for testing\n",
    "sample_us_dict = dict(list(us_dict.items())[:3])\n",
    "\n",
    "sample_us_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ad457",
   "metadata": {},
   "source": [
    "#### Create functions to make single-turn API requests.\n",
    "\n",
    "Simulates creating a new chat for each user story, so each user story is processed by the LLM in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ffa868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format model name\n",
    "def format_model_name(model):\n",
    "    return model.replace('/', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e504bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up request parameters\n",
    "def build_openrouter_request_data(model, or_token, us_text, system_prompt=None, temperature=0.8):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {or_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [],\n",
    "        \"temperature\": temperature,\n",
    "        \"provider\": {\n",
    "            \"data_collection\": \"deny\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if system_prompt is not None:\n",
    "        data[\"messages\"].append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    data[\"messages\"].append({\"role\": \"user\", \"content\": f\"User story: {us_text}\"})\n",
    "\n",
    "    return url, headers, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43cb2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make OpenRouter API request \n",
    "# NOTE: 1) this function uses the standard Requests library, so is blocking/synchronous, i.e., each request waits for previous to complete\n",
    "# NOTE: 2) this function simulates creating a new chat for each user story\n",
    "def openrouter_request(model, or_token, us_id, us_text, system_prompt=None, temperature=0.8):\n",
    "    url, headers, data = build_openrouter_request_data(model, or_token, us_text, system_prompt, temperature)\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        created = response.json().get(\"created\", \"\")\n",
    "        response_content = response.json().get(\"choices\")[0][\"message\"][\"content\"]\n",
    "        prompt_tokens = response.json().get(\"usage\", {}).get(\"prompt_tokens\", 0)\n",
    "        completion_tokens = response.json().get(\"usage\", {}).get(\"completion_tokens\", 0)\n",
    "\n",
    "        return {\n",
    "            \"model\": format_model_name(model),\n",
    "            \"created\": created,\n",
    "            \"us_id\": us_id,\n",
    "            \"user_story\": us_text,\n",
    "            \"raw_response\": response_content,\n",
    "            \"prompt_tokens\": prompt_tokens,\n",
    "            \"completion_tokens\": completion_tokens,\n",
    "        }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Sync error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3c651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make asynchronous OpenRouter API request\n",
    "# NOTE: 1) this function uses the httpx library for async requests, i.e., it does not block while waiting for a response\n",
    "# NOTE: 2) as above, this function simulates creating a new chat for each user story\n",
    "async def openrouter_request_async(model, or_token, us_id, us_text, system_prompt=None, temperature=0.8):\n",
    "    url, headers, data = build_openrouter_request_data(model, or_token, us_text, system_prompt, temperature)\n",
    "\n",
    "    try:\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.post(url, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            json_data = response.json()\n",
    "            created = json_data.get(\"created\", \"\")\n",
    "            response_content = json_data.get(\"choices\")[0][\"message\"][\"content\"]\n",
    "            prompt_tokens = json_data.get(\"usage\", {}).get(\"prompt_tokens\", 0)\n",
    "            completion_tokens = json_data.get(\"usage\", {}).get(\"completion_tokens\", 0)\n",
    "\n",
    "            return {\n",
    "                \"model\": format_model_name(model),\n",
    "                \"created\": created,\n",
    "                \"us_id\": us_id,\n",
    "                \"user_story\": us_text,\n",
    "                \"raw_response\": response_content,\n",
    "                \"prompt_tokens\": prompt_tokens,\n",
    "                \"completion_tokens\": completion_tokens\n",
    "            }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Async error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b14c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "semaphore = asyncio.Semaphore(5)  # Limit concurrent requests to 5 to avoid rate limiting\n",
    "\n",
    "# Function to make limited concurrent asynchronous OpenRouter API requests\n",
    "async def limited_openrouter_request(model, or_token, us_id, us_text, system_prompt=None, temperature=0.8):\n",
    "    async with semaphore:\n",
    "        return await openrouter_request_async(model, or_token, us_id, us_text, system_prompt, temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42d43d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a QA Engineer. Please generate a complete Gherkin feature file with 3-5 realistic, testable scenarios for the user story below. Please return the Gherkin only, without comments or explanations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e02c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llms = [\"openai/gpt-4o-mini\", \"meta-llama/llama-3.1-70b-instruct\"]\n",
    "llms = [\"openai/gpt-4o-mini\", \"google/gemini-2.0-flash-001\"]\n",
    "\n",
    "# Main function to orchestrate asynchronous OpenRouter API requests\n",
    "async def main():\n",
    "    tasks = [\n",
    "        limited_openrouter_request(model, or_token, us_id, user_story, system_prompt=system_prompt)\n",
    "        for us_id, user_story in sample_us_dict.items()\n",
    "        for model in llms\n",
    "    ]\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "results = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1247d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdc5631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>created</th>\n",
       "      <th>us_id</th>\n",
       "      <th>user_story</th>\n",
       "      <th>raw_response</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai-gpt-4o-mini</td>\n",
       "      <td>1762354426</td>\n",
       "      <td>g04-recycling_1</td>\n",
       "      <td>As a user, I want to click on the address, so ...</td>\n",
       "      <td>```gherkin\\nFeature: Open address in Google Ma...</td>\n",
       "      <td>83</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google-gemini-2.0-flash-001</td>\n",
       "      <td>1762354426</td>\n",
       "      <td>g04-recycling_1</td>\n",
       "      <td>As a user, I want to click on the address, so ...</td>\n",
       "      <td>```gherkin\\nFeature: Address Link Opens Google...</td>\n",
       "      <td>70</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai-gpt-4o-mini</td>\n",
       "      <td>1762354426</td>\n",
       "      <td>g04-recycling_2</td>\n",
       "      <td>As a user, I want to be able to anonymously vi...</td>\n",
       "      <td>```gherkin\\nFeature: Anonymous Viewing of Publ...</td>\n",
       "      <td>87</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google-gemini-2.0-flash-001</td>\n",
       "      <td>1762354426</td>\n",
       "      <td>g04-recycling_2</td>\n",
       "      <td>As a user, I want to be able to anonymously vi...</td>\n",
       "      <td>```gherkin\\nFeature: Anonymous User Views Publ...</td>\n",
       "      <td>74</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai-gpt-4o-mini</td>\n",
       "      <td>1762354426</td>\n",
       "      <td>g04-recycling_3</td>\n",
       "      <td>As a user, I want to be able to enter my zip c...</td>\n",
       "      <td>```gherkin\\nFeature: Nearby Recycling Faciliti...</td>\n",
       "      <td>92</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model     created            us_id  \\\n",
       "0           openai-gpt-4o-mini  1762354426  g04-recycling_1   \n",
       "1  google-gemini-2.0-flash-001  1762354426  g04-recycling_1   \n",
       "2           openai-gpt-4o-mini  1762354426  g04-recycling_2   \n",
       "3  google-gemini-2.0-flash-001  1762354426  g04-recycling_2   \n",
       "4           openai-gpt-4o-mini  1762354426  g04-recycling_3   \n",
       "\n",
       "                                          user_story  \\\n",
       "0  As a user, I want to click on the address, so ...   \n",
       "1  As a user, I want to click on the address, so ...   \n",
       "2  As a user, I want to be able to anonymously vi...   \n",
       "3  As a user, I want to be able to anonymously vi...   \n",
       "4  As a user, I want to be able to enter my zip c...   \n",
       "\n",
       "                                        raw_response  prompt_tokens  \\\n",
       "0  ```gherkin\\nFeature: Open address in Google Ma...             83   \n",
       "1  ```gherkin\\nFeature: Address Link Opens Google...             70   \n",
       "2  ```gherkin\\nFeature: Anonymous Viewing of Publ...             87   \n",
       "3  ```gherkin\\nFeature: Anonymous User Views Publ...             74   \n",
       "4  ```gherkin\\nFeature: Nearby Recycling Faciliti...             92   \n",
       "\n",
       "   completion_tokens  \n",
       "0                262  \n",
       "1                310  \n",
       "2                307  \n",
       "3                333  \n",
       "4                374  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5fe8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../single_turn_test_5-11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f001410",
   "metadata": {},
   "source": [
    "#### Create functions to make multi-turn API requests.\n",
    "\n",
    "Simulating an ongoing LLM chat interaction, where the chat history is appended to the start of each new user chat turn &mdash; so multiple user stories can be process in the same chat interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad8f8ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chat logs directory\n",
    "chat_log_dir = experiment_dir / \"chat_logs\"\n",
    "os.makedirs(chat_log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3708c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get path for backup chat log file with timestamp\n",
    "# def backup_file_path(chat_log_dir, model):\n",
    "#     timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#     file_path = chat_log_dir / model / f\"chat_log_{timestamp}.json\"\n",
    "\n",
    "#     return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e29d885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to save multi-turn chat to active log file\n",
    "def save_conversation(log_dir, conversation):\n",
    "    filepath = log_dir / \"active.json\"\n",
    "\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        \n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(conversation, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "965ba338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to back up active chat log file\n",
    "def backup_active_file(log_dir):\n",
    "    active_file_path = log_dir / \"active.json\"\n",
    "\n",
    "    if os.path.exists(active_file_path):\n",
    "        backup_file_path = log_dir / f\"chat_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        shutil.copy(active_file_path, backup_file_path)\n",
    "\n",
    "        return backup_file_path\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64d0e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"You are a QA Engineer. For each user story I give you, please generate a complete Gherkin feature file with at least three realistic, testable scenarios. Try to cover: 1. The happy path (expected successful flow), 2. At least one edge case, 3. At least one error or failure condition. Please return the Gherkin only, without comments or explanation.\"\n",
    "# reminder = \"Reminder: your task is to generate a complete Gherkin feature file with at least three realistic, testable scenarios for the user story I give you, returning only the Gherkin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c7ab330",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a QA Engineer. For each user story I give you, please generate a complete Gherkin feature file with 3-5 realistic, testable scenarios. Please return the Gherkin only, without comments or explanation.\"\n",
    "reminder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80e8577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to conduct multi-turn chat with model over multiple user stories and log the conversation\n",
    "async def chat_with_model(model, or_token, log_dir, user_stories, system_prompt=None, reminder=None, temperature=0.8):\n",
    "    # Create model-specific log directory, if it doesn't exist\n",
    "    model_log_dir = log_dir / format_model_name(model)\n",
    "    os.makedirs(model_log_dir, exist_ok=True)\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {or_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    print(\"Starting chat for model:\", model)\n",
    "\n",
    "    # Messages list will hold the full conversation history, updated after each turn\n",
    "    messages = []\n",
    "\n",
    "    # Conversation log dict will hold the structured log to be saved to file\n",
    "    conversation_log = {\n",
    "        \"model\": model,\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"conversation_turns\": []\n",
    "    }\n",
    "\n",
    "    # Completed stories will hold us_ids of already processed user stories\n",
    "    completed_stories = []\n",
    "\n",
    "    # Add system prompt to messages - prompt is sent once at start of conversation\n",
    "    if system_prompt is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        conversation_log[\"system_prompt\"] = system_prompt\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        for us_id, us_text in user_stories.items():\n",
    "            if us_id in completed_stories: # This is probably redundant now but will be useful when resuming from file (functionality to be added)\n",
    "                print(f\"Skipping already completed user story: {us_id}\")\n",
    "                continue\n",
    "\n",
    "            turn = {\"user\": {}, \"assistant\": {}}\n",
    "\n",
    "            if reminder is not None:\n",
    "                # Add reminder message before each user story\n",
    "                messages.append({\"role\": \"user\", \"content\": reminder})\n",
    "                # conversation_log[\"conversation_turns\"].append({\"role\": \"user\", \"content\": reminder}) # Log user messages\n",
    "                turn[\"user\"][\"reminder\"] = reminder\n",
    "            \n",
    "            user_message = f\"User story: {us_text}\"\n",
    "            \n",
    "            messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "            # conversation_log[\"conversation_turns\"].append({\"role\": \"user\", \"content\": user_message, \"us_id\": us_id}) # Log user messages\n",
    "\n",
    "            turn[\"user\"][\"content\"] = user_message\n",
    "            turn[\"user\"][\"us_id\"] = us_id\n",
    "\n",
    "            try:\n",
    "                response = await client.post(\n",
    "                    url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                    headers=headers,\n",
    "                    json={\n",
    "                        \"model\": model,\n",
    "                        \"messages\": messages,\n",
    "                        \"temperature\": temperature,\n",
    "                        \"provider\": {\"data_collection\": \"deny\"},\n",
    "                    },\n",
    "                )\n",
    "                \n",
    "                response.raise_for_status()\n",
    "\n",
    "                data = response.json()\n",
    "                \n",
    "                assistant_response = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "                created = data.get(\"created\", \"\")\n",
    "                prompt_tokens = data.get(\"usage\", {}).get(\"prompt_tokens\", 0)\n",
    "                completion_tokens = data.get(\"usage\", {}).get(\"completion_tokens\", 0)\n",
    "\n",
    "                messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "                # conversation_log[\"conversation_turns\"].append({\"role\": \"assistant\", \"content\": assistant_response, \"created\": created, \"prompt_tokens\": prompt_tokens, \"completion_tokens\": completion_tokens}) # Log assistant messages\n",
    "\n",
    "                turn[\"assistant\"][\"content\"] = assistant_response\n",
    "                turn[\"assistant\"][\"created\"] = created\n",
    "                turn[\"assistant\"][\"prompt_tokens\"] = prompt_tokens\n",
    "                turn[\"assistant\"][\"completion_tokens\"] = completion_tokens\n",
    "\n",
    "                completed_stories.append(us_id)\n",
    "\n",
    "                conversation_log[\"conversation_turns\"].append(turn)\n",
    "\n",
    "                # Save updated conversation log to active file after each turn\n",
    "                save_conversation(model_log_dir, conversation_log)\n",
    "                # print(messages)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during API request for user story {us_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Save time-stamped backup of active chat log file\n",
    "    backup_active_file(model_log_dir)\n",
    "    \n",
    "    return conversation_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95c9e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_log_dir = experiment_dir / \"chat_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bf6037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat for model: openai/gpt-4o-mini\n",
      "Starting chat for model: google/gemini-2.0-flash-001\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    results = await asyncio.gather(*[\n",
    "        chat_with_model(model, or_token, experiment_log_dir, sample_us_dict, system_prompt=system_prompt)\n",
    "        for model in llms\n",
    "    ])\n",
    "    return results\n",
    "\n",
    "results = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "573a247a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'openai/gpt-4o-mini',\n",
       "  'system_prompt': 'You are a QA Engineer. For each user story I give you, please generate a complete Gherkin feature file with 3-5 realistic, testable scenarios. Please return the Gherkin only, without comments or explanation.',\n",
       "  'conversation_turns': [{'role': 'user',\n",
       "    'content': 'User story: As a user, I want to click on the address, so that it takes me to a new tab with Google Maps.',\n",
       "    'us_id': 'g04-recycling_1'},\n",
       "   {'user': {'content': 'User story: As a user, I want to click on the address, so that it takes me to a new tab with Google Maps.',\n",
       "     'us_id': 'g04-recycling_1'},\n",
       "    'assistant': {'content': '```gherkin\\nFeature: Address Link Navigation\\n\\n  Scenario: User clicks on the address link\\n    Given the user is on the homepage\\n    When the user clicks on the address link\\n    Then a new tab should open with Google Maps\\n    And the address should be correctly displayed in the URL of the new tab\\n\\n  Scenario: User clicks on the address link while using a mobile device\\n    Given the user is on the mobile version of the homepage\\n    When the user taps on the address link\\n    Then a new tab should open with Google Maps\\n    And the address should be correctly displayed in the URL of the new tab\\n\\n  Scenario: User clicks on the address link and the browser blocks pop-ups\\n    Given the user is on the homepage\\n    When the user clicks on the address link\\n    And the browser blocks pop-ups\\n    Then an alert should be displayed informing the user that the pop-up has been blocked\\n    And the user should have the option to allow pop-ups\\n\\n  Scenario: User right-clicks on the address link\\n    Given the user is on the homepage\\n    When the user right-clicks on the address link\\n    Then a context menu should appear with the option to \"Open link in new tab\"\\n  \\n  Scenario: User clicks on the address link from a different page\\n    Given the user is on a different page of the website\\n    When the user clicks on the address link\\n    Then a new tab should open with Google Maps\\n    And the address should be correctly displayed in the URL of the new tab\\n```',\n",
       "     'created': 1762362580,\n",
       "     'prompt_tokens': 86,\n",
       "     'completion_tokens': 322}},\n",
       "   {'role': 'user',\n",
       "    'content': 'User story: As a user, I want to be able to anonymously view public information, so that I know about recycling centers near me before creating an account.',\n",
       "    'us_id': 'g04-recycling_2'},\n",
       "   {'user': {'content': 'User story: As a user, I want to be able to anonymously view public information, so that I know about recycling centers near me before creating an account.',\n",
       "     'us_id': 'g04-recycling_2'},\n",
       "    'assistant': {'content': '```gherkin\\nFeature: Anonymous Viewing of Public Information\\n\\n  Scenario: User views recycling centers without logging in\\n    Given the user is on the recycling information page\\n    When the user browses the list of recycling centers\\n    Then the user should see a list of available recycling centers\\n    And no account creation prompt should be displayed\\n\\n  Scenario: User searches for recycling centers by location\\n    Given the user is on the recycling information page\\n    When the user enters their location in the search bar\\n    And clicks on the search button\\n    Then the user should see a list of recycling centers near the entered location\\n    And no account creation prompt should be displayed\\n\\n  Scenario: User filters recycling centers by type without logging in\\n    Given the user is on the recycling information page\\n    When the user selects a type of recycling center from the filter options\\n    Then the user should see a filtered list of recycling centers\\n    And no account creation prompt should be displayed\\n\\n  Scenario: User navigates away from the recycling centers page\\n    Given the user is viewing the recycling centers\\n    When the user navigates to another page on the website\\n    Then the user should not be prompted to create an account\\n\\n  Scenario: User accesses recycling center information from a shared link\\n    Given the user clicks on a shared link to a recycling center\\n    When the user views the recycling center information\\n    Then the user should see the details of the recycling center\\n    And no account creation prompt should be displayed\\n```',\n",
       "     'created': 1762362590,\n",
       "     'prompt_tokens': 448,\n",
       "     'completion_tokens': 309}},\n",
       "   {'role': 'user',\n",
       "    'content': 'User story: As a user, I want to be able to enter my zip code and get a list of nearby recycling facilities, so that I can determine which ones I should consider.',\n",
       "    'us_id': 'g04-recycling_3'},\n",
       "   {'user': {'content': 'User story: As a user, I want to be able to enter my zip code and get a list of nearby recycling facilities, so that I can determine which ones I should consider.',\n",
       "     'us_id': 'g04-recycling_3'},\n",
       "    'assistant': {'content': '```gherkin\\nFeature: Zip Code Search for Nearby Recycling Facilities\\n\\n  Scenario: User enters a valid zip code\\n    Given the user is on the recycling facilities page\\n    When the user enters a valid zip code in the search field\\n    And clicks on the \"Search\" button\\n    Then the user should see a list of nearby recycling facilities\\n    And the facilities should be sorted by distance from the entered zip code\\n\\n  Scenario: User enters an invalid zip code\\n    Given the user is on the recycling facilities page\\n    When the user enters an invalid zip code in the search field\\n    And clicks on the \"Search\" button\\n    Then an error message should be displayed indicating that the zip code is invalid\\n    And no list of facilities should be shown\\n\\n  Scenario: User enters a zip code with no nearby facilities\\n    Given the user is on the recycling facilities page\\n    When the user enters a zip code that has no recycling facilities nearby\\n    And clicks on the \"Search\" button\\n    Then the user should see a message indicating that no facilities were found\\n    And no list of facilities should be displayed\\n\\n  Scenario: User enters a zip code and sees loading indicators\\n    Given the user is on the recycling facilities page\\n    When the user enters a valid zip code in the search field\\n    And clicks on the \"Search\" button\\n    Then a loading indicator should be displayed while the search is processing\\n    And once the results are ready, the list of nearby recycling facilities should be shown\\n\\n  Scenario: User clears the zip code search\\n    Given the user has entered a zip code and viewed the results\\n    When the user clicks on the \"Clear\" button\\n    Then the zip code input field should be empty\\n    And the list of recycling facilities should be cleared\\n```',\n",
       "     'created': 1762362600,\n",
       "     'prompt_tokens': 802,\n",
       "     'completion_tokens': 371}}]},\n",
       " {'model': 'google/gemini-2.0-flash-001',\n",
       "  'system_prompt': 'You are a QA Engineer. For each user story I give you, please generate a complete Gherkin feature file with 3-5 realistic, testable scenarios. Please return the Gherkin only, without comments or explanation.',\n",
       "  'conversation_turns': [{'role': 'user',\n",
       "    'content': 'User story: As a user, I want to click on the address, so that it takes me to a new tab with Google Maps.',\n",
       "    'us_id': 'g04-recycling_1'},\n",
       "   {'user': {'content': 'User story: As a user, I want to click on the address, so that it takes me to a new tab with Google Maps.',\n",
       "     'us_id': 'g04-recycling_1'},\n",
       "    'assistant': {'content': '```gherkin\\nFeature: Address Link Opens Google Maps in New Tab\\n\\n  Scenario: Clicking address opens Google Maps in a new tab\\n    Given I am on the contact page\\n    When I click on the address link\\n    Then a new tab should open\\n    And the new tab\\'s URL should contain \"google.com/maps\"\\n    And the new tab\\'s URL should contain the address\\n\\n  Scenario: Address is present and clickable\\n    Given I am on the contact page\\n    Then the address should be displayed\\n    And the address link should be enabled\\n\\n  Scenario: Address link contains the correct address\\n    Given I am on the contact page\\n    Then the address link\\'s URL should contain the correct address\\n\\n  Scenario: No other links open Google Maps\\n    Given I am on the contact page\\n    When I click on any other link\\n    Then a new tab should not open with Google Maps\\n```\\n',\n",
       "     'created': 1762362580,\n",
       "     'prompt_tokens': 73,\n",
       "     'completion_tokens': 195}},\n",
       "   {'role': 'user',\n",
       "    'content': 'User story: As a user, I want to be able to anonymously view public information, so that I know about recycling centers near me before creating an account.',\n",
       "    'us_id': 'g04-recycling_2'},\n",
       "   {'user': {'content': 'User story: As a user, I want to be able to anonymously view public information, so that I know about recycling centers near me before creating an account.',\n",
       "     'us_id': 'g04-recycling_2'},\n",
       "    'assistant': {'content': '```gherkin\\nFeature: Anonymous User Access to Recycling Center Information\\n\\n  Scenario: View recycling centers without logging in\\n    Given I am an anonymous user\\n    When I navigate to the recycling center page\\n    Then I should see a list of recycling centers\\n    And I should not be prompted to log in or sign up\\n\\n  Scenario: View recycling center details without logging in\\n    Given I am an anonymous user\\n    When I navigate to a specific recycling center\\'s details page\\n    Then I should see the recycling center\\'s information (e.g., address, hours)\\n    And I should not be prompted to log in or sign up\\n\\n  Scenario: Search for recycling centers without logging in\\n    Given I am an anonymous user\\n    When I search for recycling centers by location \"San Francisco\"\\n    Then I should see a list of recycling centers in San Francisco\\n    And I should not be prompted to log in or sign up\\n\\n  Scenario: Filter recycling centers without logging in\\n    Given I am an anonymous user\\n    When I filter recycling centers by \"Plastic Recycling\"\\n    Then I should see a list of recycling centers that accept plastic\\n    And I should not be prompted to log in or sign up\\n```',\n",
       "     'created': 1762362582,\n",
       "     'prompt_tokens': 299,\n",
       "     'completion_tokens': 255}},\n",
       "   {'role': 'user',\n",
       "    'content': 'User story: As a user, I want to be able to enter my zip code and get a list of nearby recycling facilities, so that I can determine which ones I should consider.',\n",
       "    'us_id': 'g04-recycling_3'},\n",
       "   {'user': {'content': 'User story: As a user, I want to be able to enter my zip code and get a list of nearby recycling facilities, so that I can determine which ones I should consider.',\n",
       "     'us_id': 'g04-recycling_3'},\n",
       "    'assistant': {'content': '```gherkin\\nFeature: Find Recycling Facilities by Zip Code\\n\\n  Scenario: Search for recycling facilities by valid zip code\\n    Given I am on the recycling facility search page\\n    When I enter a valid zip code \"90210\"\\n    And I click the search button\\n    Then I should see a list of recycling facilities near \"90210\"\\n\\n  Scenario: Search results display distances to facilities\\n    Given I have searched for recycling facilities using zip code \"90210\"\\n    Then each facility in the search results should display its distance from \"90210\"\\n\\n  Scenario: Search for recycling facilities with no results\\n    Given I am on the recycling facility search page\\n    When I enter a valid zip code with no nearby facilities \"00000\"\\n    And I click the search button\\n    Then I should see a message indicating no facilities were found\\n    And I should not see any recycling facilities listed\\n\\n  Scenario: Handle invalid zip code input\\n    Given I am on the recycling facility search page\\n    When I enter an invalid zip code \"ABCDE\"\\n    And I click the search button\\n    Then I should see an error message indicating the zip code is invalid\\n\\n  Scenario: Search with an empty zip code\\n    Given I am on the recycling facility search page\\n    When I click the search button without entering a zip code\\n    Then I should see an error message indicating the zip code is required\\n```',\n",
       "     'created': 1762362584,\n",
       "     'prompt_tokens': 591,\n",
       "     'completion_tokens': 309}}]}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model_result in results:\n",
    "    model = model_result.get(\"model\")\n",
    "    system_prompt = model_result.get(\"system_prompt\")\n",
    "    conversations = model_result.get(\"conversation\", [])\n",
    "    \n",
    "    for conv in conversations:\n",
    "        if \n",
    "        us_id = conv.get(\"us_id\")\n",
    "        user_story = conv.get(\"user_story\")\n",
    "        assistant_response = conv.get(\"assistant_response\")\n",
    "\n",
    "        created = conv.get(\"raw_response\", {}).get(\"created\")\n",
    "        # Token counts (if available)\n",
    "        usage = conv.get(\"raw_response\", {}).get(\"usage\", {})\n",
    "        prompt_tokens = usage.get(\"prompt_tokens\")\n",
    "        completion_tokens = usage.get(\"completion_tokens\")\n",
    "        # total_tokens = usage.get(\"total_tokens\")\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": model,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"us_id\": us_id,\n",
    "            \"user_story\": user_story,\n",
    "            \"assistant_response\": assistant_response,\n",
    "            \"prompt_tokens\": prompt_tokens,\n",
    "            \"completion_tokens\": completion_tokens,\n",
    "            \"created\": created\n",
    "            # \"total_tokens\": total_tokens\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# # Optional: order columns\n",
    "# df = df[\n",
    "#     [\n",
    "#         \"model\",\n",
    "#         \"timestamp\",\n",
    "#         \"us_id\",\n",
    "#         \"user_story\",\n",
    "#         \"assistant_response\",\n",
    "#         \"prompt_tokens\",\n",
    "#         \"completion_tokens\",\n",
    "#         \"total_tokens\"\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# Preview\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1deeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd9a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b859a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify user stories that only appear once in the dataset i.e. those for which a model request failed\n",
    "# story_counts = df[\"user_story\"].value_counts()\n",
    "# missing_stories = story_counts[story_counts == 1].index.tolist()\n",
    "\n",
    "# missing_stories_df = df[df[\"user_story\"].isin(missing_stories)]\n",
    "# missing_stories_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fe08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Request missing Gherkin for user stories that only appear once in the dataset\n",
    "# results = []\n",
    "\n",
    "# for index, row in missing_stories_df.iterrows():\n",
    "#     user_story = row['user_story']\n",
    "#     model = row['model']\n",
    "#     missing_model = (set(models) - {model}).pop()  # Get the other model\n",
    "\n",
    "#     print(f\"Requesting missing Gherkin for user story: {row['user_story']} using model: {missing_model}\")\n",
    "\n",
    "#     result = openrouter_request(user_story, missing_model, or_token)\n",
    "#     results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d190c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793e81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gherkin_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
